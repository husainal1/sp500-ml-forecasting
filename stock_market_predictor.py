# -*- coding: utf-8 -*-
"""Stock Market Predictor.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_2uuc7SOiPuKShv5QR13dYnocfWFvgRT
"""

import yfinance as yf

sp500 = yf.Ticker("^GSPC")

sp500 = sp500.history(period="max")

sp500

sp500.index

sp500.plot.line(y="Close", use_index=True)

del sp500["Dividends"]
del sp500["Stock Splits"]

sp500["Tomorrow"] = sp500["Close"].shift(-1)

sp500

sp500["Target"] = (sp500["Tomorrow"] > sp500["Close"]).astype(int)

sp500

sp500 = sp500.loc["1990-01-01":].copy()

sp500

import yfinance as yf
import pandas as pd
from sklearn.ensemble import RandomForestClassifier

sp500 = yf.Ticker("^GSPC")
sp500 = sp500.history(period="max")
del sp500["Dividends"]
del sp500["Stock Splits"]
sp500["Tomorrow"] = sp500["Close"].shift(-1)
sp500["Target"] = (sp500["Tomorrow"] > sp500["Close"]).astype(int)
sp500 = sp500.loc["1990-01-01":].copy()

model = RandomForestClassifier(n_estimators=100, min_samples_split=100, random_state=1)

train = sp500.iloc[:-100]
test = sp500.iloc[-100:]

predictors = ["Close", "Volume", "Open", "High", "Low"]
model.fit(train[predictors], train["Target"])

from sklearn.metrics import precision_score

preds = model.predict(test[predictors])
preds = pd.Series(preds, index=test.index)
precision_score(test["Target"], preds)

import pandas as pd

preds = pd.Series(preds, index=test.index)

# Import libraries for fetching data from FRED
import pandas_datareader as pdr
import datetime as dt

# Define start date and fetch CPI and Federal Funds Rate data from FRED
start = dt.datetime(1990, 1, 1)
cpi = pdr.get_data_fred('CPIAUCSL', start=start)
fed_funds_rate = pdr.get_data_fred('DFF', start=start)

import yfinance as yf
import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import precision_score

# Fetch and prepare S&P 500 data
sp500 = yf.Ticker("^GSPC")
sp500 = sp500.history(period="max")
del sp500["Dividends"]
del sp500["Stock Splits"]
sp500["Tomorrow"] = sp500["Close"].shift(-1)
sp500["Target"] = (sp500["Tomorrow"] > sp500["Close"]).astype(int)
sp500 = sp500.loc["1990-01-01":].copy()

# Define horizons and create technical indicators
horizons = [2,5,60,250,1000]
new_predictors = []

for horizon in horizons:
    rolling_averages = sp500.rolling(horizon).mean()
    ratio_column = f"Close_Ratio_{horizon}"
    sp500[ratio_column] = sp500["Close"] / rolling_averages["Close"]
    trend_column = f"Trend_{horizon}"
    sp500[trend_column] = sp500.shift(1).rolling(horizon).sum()["Target"]
    new_predictors += [ratio_column, trend_column]

# Drop initial NaN values introduced by rolling calculations
sp500 = sp500.dropna()

# Initialize and train the model
model = RandomForestClassifier(n_estimators=200, min_samples_split=50, random_state=1)

# Define a function to make predictions with a probability threshold
def predict(train, test, predictors, model):
    model.fit(train[predictors], train["Target"])
    preds = model.predict_proba(test[predictors])[:,1]
    preds [preds >= .6] = 1
    preds [preds < .6] = 0
    preds = pd.Series(preds, index=test.index, name="Predictions")
    combined = pd.concat([test["Target"], preds], axis=1)
    return combined

# Define a function for backtesting the model over time
def backtest(data, model, predictors, start=2500, step=250):
    all_predictions = []
    for id in range(start, data.shape[0], step):
        train = data.iloc[0:id].copy()
        test = data.iloc[id:(id + step)].copy()
        predictions = predict(train, test, predictors, model)
        all_predictions.append(predictions)
    return pd.concat(all_predictions)


# Run backtesting with the data and new predictors
predictions = backtest(sp500, model, new_predictors)

# Display prediction counts and precision score
print(predictions["Predictions"].value_counts())
precision_after = precision_score(predictions["Target"], predictions["Predictions"])
print(precision_after)

# Compare precision before and after adding economic factors (using the original precision before economic factors)
precision_before = 0.5296324081020255
print(f"Precision before adding economic factors: {precision_before}")
print(f"Precision after adding economic factors: {precision_after}")

# Analyze the results, including precision and recall for predicting 1
if precision_after > precision_before:
    print("Adding economic factors improved precision.")
elif precision_after < precision_before:
    print("Adding economic factors decreased precision.")
else:
    print("Adding economic factors did not change precision.")

print("\nAnalysis of Predictions:")
print(predictions.value_counts())

from sklearn.metrics import recall_score
precision_on_1 = precision_score(predictions["Target"], predictions["Predictions"], pos_label=1)
print(f"Precision when predicting 1: {precision_on_1}")
recall_on_1 = recall_score(predictions["Target"], predictions["Predictions"], pos_label=1)
print(f"Recall when predicting 1: {recall_on_1}")

if precision_on_1 == 1.0 and predictions["Predictions"].sum() < predictions["Target"].sum():
    print("\nExplanation: The model is highly conservative and only predicts the market goes up when it's very certain (resulting in 1.0 precision on those few predictions). However, it misses many instances where the market actually went up (low recall). This leads to an imbalanced prediction distribution.")
elif precision_on_1 < precision_before:
     print("\nExplanation: Adding economic factors slightly decreased precision. The model is still making a limited number of positive predictions compared to the actual number of upward movements.")

combined = pd.concat([sp500["Target"], preds], axis=1)

combined.plot()

# Define a function to make predictions
def predict(train, test, predictors, model):
    # Fit the model to the training data and make predictions
    model.fit(train[predictors], train["Target"])
    preds = model.predict(test[predictors])
    # Combine actual target values and predictions into a single DataFrame
    preds = pd.Series(preds, index=test.index, name="Predictions")
    combined = pd.concat([test["Target"], preds], axis=1)
    return combined

# Define a function for backtesting the model over time
def backtest(data, model, predictors, start=2500, step=250):
    all_predictions = []

    # Iterate through the data, training and testing the model in steps
    for id in range(start, data.shape[0], step):
        train = data.iloc[0:id].copy()
        test = data.iloc[id:(id + step)].copy()
        # Make predictions for the current test set
        predictions = predict(train, test, predictors, model)
        all_predictions.append(predictions)

    # Concatenate predictions from all backtesting steps
    return pd.concat(all_predictions)

predictions = backtest(sp500, model, predictors)

predictions["Predictions"].value_counts()

precision_score(predictions["Target"], predictions["Predictions"])

predictions["Target"].value_counts() / predictions.shape[0]

# Define horizons for rolling calculations and initialize list for new predictors
horizons = [2,5,60,250,1000]
new_predictors = []

# Create new technical indicators based on rolling averages and trends for each horizon
for horizon in horizons:
    rolling_averages = sp500.rolling(horizon).mean()

    # Calculate ratio of closing price to rolling average
    ratio_column = f"Close_Ratio_{horizon}"
    sp500[ratio_column] = sp500["Close"] / rolling_averages["Close"]

    # Calculate trend (sum of targets in rolling window)
    trend_column = f"Trend_{horizon}"
    sp500[trend_column] = sp500.shift(1).rolling(horizon).sum()["Target"]

    # Add new predictor names to the list
    new_predictors += [ratio_column, trend_column]

sp500 = sp500.dropna()

sp500

model = RandomForestClassifier(n_estimators=200, min_samples_split=50, random_state=1)

# Define a function to make predictions with a probability threshold
def predict(train, test, predictors, model):
    # Fit the model and predict probabilities
    model.fit(train[predictors], train["Target"])
    preds = model.predict_proba(test[predictors])[:,1]
    # Apply a threshold of 0.6 to convert probabilities to binary predictions
    preds [preds >= .6] = 1
    preds [preds < .6] = 0
    # Convert predictions to Series and combine with actual targets
    preds = pd.Series(preds, index=test.index, name="Predictions")
    combined = pd.concat([test["Target"], preds], axis=1)
    return combined

predictions = backtest(sp500, model, new_predictors)

predictions["Predictions"].value_counts()

precision_score(predictions["Target"], predictions["Predictions"])